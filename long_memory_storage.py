import os
from langchain_community.document_loaders import DirectoryLoader, PyPDFLoader, TextLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import FAISS
from config import (
    OPENAI_API_KEY,
    OPENAI_BASE_URL,
    EMBEDDING_MODEL,
    PERSON_KB_PATH,
)

# å®šä¹‰æ–‡ä»¶å¤¹è·¯å¾„
DATA_PATH    = "person_basic_info"  # ä½ çš„æ–‡æ¡£æ‰€åœ¨æ–‡ä»¶å¤¹
DB_SAVE_PATH = PERSON_KB_PATH     # å‘é‡æ•°æ®åº“ä¿å­˜è·¯å¾„

def create_vector_db():
    print("ğŸ”„ å¼€å§‹åŠ è½½æ–‡æ¡£...")
    
    docs = []
    
    # 1. åŠ è½½ PDF æ–‡ä»¶
    if os.path.exists(DATA_PATH):
        # åŠ è½½ PDF
        pdf_loader = DirectoryLoader(DATA_PATH, glob="**/*.pdf", loader_cls=PyPDFLoader)
        pdf_docs = pdf_loader.load()
        docs.extend(pdf_docs)
        print("å·²åŠ è½½çš„ PDF æ–‡ä»¶:", list(set(doc.metadata["source"] for doc in pdf_docs)))
        # print(f"   - åŠ è½½äº† {len(pdf_docs)} ä¸ª PDF æ–‡æ¡£")

    else:
        print(f"âŒ é”™è¯¯ï¼šæ‰¾ä¸åˆ°æ–‡ä»¶å¤¹ '{DATA_PATH}'ï¼Œè¯·å…ˆåˆ›å»ºå¹¶æ”¾å…¥æ–‡ä»¶ã€‚")
        return

    if not docs:
        print("âŒ æœªæ‰¾åˆ°ä»»ä½•æ–‡ä»¶ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶å¤¹å†…å®¹ã€‚")
        return

    # 2. æ–‡æœ¬åˆ‡åˆ† (Text Splitter)
    # ä½¿ç”¨ä¸ä½  Notebook ä¸­ç±»ä¼¼çš„åˆ‡åˆ†å‚æ•°
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=1000,  # æ¯ä¸ªå—çš„å¤§å°
        chunk_overlap=200 # ä¸Šä¸‹æ–‡é‡å éƒ¨åˆ†
    )
    splits = text_splitter.split_documents(docs)
    print(f"âœ‚ï¸  æ–‡æ¡£å·²åˆ‡åˆ†ä¸º {len(splits)} ä¸ªç‰‡æ®µ")

    # 3. åˆå§‹åŒ– Embedding æ¨¡å‹
    embeddings = OpenAIEmbeddings(
        base_url=OPENAI_BASE_URL,
        api_key=OPENAI_API_KEY,
        model=EMBEDDING_MODEL # æ¨èä½¿ç”¨æ­¤æ¨¡å‹ï¼Œæ€§ä»·æ¯”é«˜
    )

    # 4. å‘é‡åŒ–å¹¶å­˜å…¥ FAISS
    print("zzZ  æ­£åœ¨ç”Ÿæˆå‘é‡å¹¶å­˜å…¥ FAISS (è¿™å¯èƒ½éœ€è¦ä¸€ç‚¹æ—¶é—´)...")
    vector_store = FAISS.from_documents(splits, embeddings)

    # 5. ä¿å­˜åˆ°æœ¬åœ°ç£ç›˜
    vector_store.save_local(DB_SAVE_PATH)
    print(f"âœ… æˆåŠŸï¼æ•°æ®åº“å·²ä¿å­˜è‡³æœ¬åœ°æ–‡ä»¶å¤¹: ./{DB_SAVE_PATH}")

# --- æµ‹è¯•åŠ è½½ä¸æ£€ç´¢ ---
def test_query(query_text):
    print(f"\nğŸ” æµ‹è¯•æ£€ç´¢: {query_text}")
    
    # é‡æ–°åŠ è½½ Embedding (ç”¨äºæŸ¥è¯¢)
    embeddings = OpenAIEmbeddings(
        base_url=OPENAI_BASE_URL,
        api_key=OPENAI_API_KEY,
        model=EMBEDDING_MODEL
    )
    
    # åŠ è½½æœ¬åœ°ä¿å­˜çš„æ•°æ®åº“
    # allow_dangerous_deserialization=True æ˜¯ä¸ºäº†åŠ è½½ pickle æ–‡ä»¶ï¼Œç¡®ä¿¡æ–‡ä»¶æ˜¯è‡ªå·±ç”Ÿæˆçš„å³å¯
    new_vector_store = FAISS.load_local(
        DB_SAVE_PATH, 
        embeddings, 
        allow_dangerous_deserialization=True
    )
    
    # æ‰§è¡Œç›¸ä¼¼åº¦æœç´¢
    results = new_vector_store.similarity_search(query_text, k=2)
    
    for i, doc in enumerate(results):
        source = doc.metadata.get("source", "æœªçŸ¥æ¥æº")
        content = doc.page_content[:100] + "..." # åªæ˜¾ç¤ºå‰100å­—
        print(f"   [ç»“æœ {i+1}] (æ¥æº: {source}):\n   {content}\n")

if __name__ == "__main__":
    # ç¬¬ä¸€æ­¥ï¼šå»ºç«‹æ•°æ®åº“
    create_vector_db()
    
    # ç¬¬äºŒæ­¥ï¼šç®€å•æµ‹è¯• (ç¡®ä¿ person_basic_info æ–‡ä»¶å¤¹å­˜åœ¨ä¸”æœ‰æ–‡ä»¶åå†è¿è¡Œ)
    # test_query("é«˜è¡€å‹é˜²æ²»çš„å…³é”®æ˜¯ä»€ä¹ˆï¼Ÿ")
